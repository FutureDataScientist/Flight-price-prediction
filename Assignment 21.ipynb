{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3b1906",
   "metadata": {},
   "source": [
    "# Assignment 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725d835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ans 1:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "video_links = soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd551dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    video_url = \"https://www.youtube.com/@PW-Foundation/videos\"+ video_links[i]['href']\n",
    "    print(video_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddace9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ans 2:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all the video thumbnails on the page\n",
    "thumbnails = soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "# Extract the URL of the video thumbnails of the first five videos\n",
    "for i in range(5):\n",
    "    thumbnail_url = thumbnails[i].find('img')['src']\n",
    "    print(thumbnail_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans3 :\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all the titles of the videos on the page\n",
    "titles = soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "# Extract the titles of the first five videos\n",
    "for i in range(5):\n",
    "    title = titles[i].find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a981e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b618d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans 4:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all the metadata of the videos on the page\n",
    "metadata = soup.find_all('div', {'class': 'metadata style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "# Extract the number of views of the first five videos\n",
    "for i in range(5):\n",
    "    views = metadata[i].find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text\n",
    "    print(views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf960c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd098e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans 5:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send an HTTP request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all the timestamps of the videos on the page\n",
    "timestamps = soup.find_all('span', {'class': 'style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "# Extract the time of posting of the first five videos\n",
    "for i in range(5):\n",
    "    time = timestamps[i].find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text\n",
    "    print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ad3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
